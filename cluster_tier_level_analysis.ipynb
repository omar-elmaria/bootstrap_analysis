{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages\n",
    "import pandas as pd\n",
    "# import bigquery\n",
    "from google.cloud import bigquery\n",
    "# from google.cloud import bigquery_storage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydata_google_auth\n",
    "credentials = pydata_google_auth.get_user_credentials(\n",
    "    ['https://www.googleapis.com/auth/bigquery'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some global inputs\n",
    "entity_id = \"PY_CL\"\n",
    "test_names = [\"'CL_20221201_R_B0_O_ElasticityCLRestaurants'\"]\n",
    "ld_lb_tg = \"Low basket, low distance\" # Low distance low basket clsuter\n",
    "hd_lb_tg = \"Low basket, high distance\" # High Distance low basket cluster\n",
    "central_tg = \"Central cluster\" # Central cluster\n",
    "ld_hb_tg = \"High basket, low distance\" # Low distance high basket cluster\n",
    "hd_hb_tg = \"High basket, high distance\" # High distance high basket cluster\n",
    "tier_1 = \"1\"\n",
    "tier_2 = \"2\"\n",
    "tier_3 = \"3\"\n",
    "tier_4 = \"4\"\n",
    "tier_5 = \"5\"\n",
    "test_start_date = \"2022-12-01\"\n",
    "test_end_date = \"2023-01-12\"\n",
    "scheme_ids = [\"'634,635'\"]\n",
    "num_bootstrap_samples = 1000 # Number of data points to have on the histogram\n",
    "cl = 0.95\n",
    "left_threshold = round((1 - cl) / 2, 4)\n",
    "right_threshold = round((1 - (1 - cl) / 2), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"\"\"with  load_scheme_data as (\n",
    "        SELECT \n",
    "            entity_id\n",
    "            , scheme_id\n",
    "            , scheme_active_from\n",
    "            , IFNULL(scheme_active_to, CURRENT_TIMESTAMP()) scheme_active_to\n",
    "            , scheme_component_configs.travel_time_config\n",
    "        FROM `fulfillment-dwh-production.cl.pricing_configuration_versions`\n",
    ")\n",
    "\n",
    " ##### LOAD ORDER DATA AND JOIN PM DATA \n",
    "\n",
    ", dps_order_raw as (\n",
    "    SELECT\n",
    "        -- Identifiers and supplementary fields     \n",
    "        -- Date and time\n",
    "        a.created_date AS created_date_utc,\n",
    "        a.order_placed_at,\n",
    "        -- Location of order\n",
    "        -- a.region,\n",
    "        a.entity_id,\n",
    "        -- a.country_code,\n",
    "        -- a.city_name,\n",
    "        -- a.city_id,\n",
    "        -- a.zone_name,\n",
    "        -- a.zone_id,\n",
    "        -- Order/customer identifiers and session data\n",
    "        a.variant,\n",
    "        -- a.experiment_id AS test_id,\n",
    "        -- b.test_name,\n",
    "        a.scheme_id,\n",
    "        -- a.vendor_price_scheme_type,\t-- The assignment type of the scheme to the vendor during the time of the order, such as \"Automatic\", \"Manual\", \"Campaign\", and \"Country Fallback\".\n",
    "        -- Vendor data and information on the delivery\n",
    "        a.vendor_id,\n",
    "        a.dps_travel_time,\n",
    "        e.cluster entity_cluster,\n",
    "        v.cluster area_cluster,\n",
    "        -- b.target_group AS target_group_bi,\n",
    "        -- a.is_in_treatment,\n",
    "        -- a.chain_id,\n",
    "        -- a.chain_name,\n",
    "        -- a.vertical_type,\n",
    "        -- a.delivery_status,\n",
    "        -- a.is_own_delivery,\n",
    "        -- a.exchange_rate\n",
    "        -- Business KPIs (These are the components of profit)\n",
    "        a.platform_order_code platform_order_code,\n",
    "        a.dps_travel_time_fee_local,\n",
    "        a.dps_delivery_fee_local dps_delivery_fee_local,\n",
    "        --avg(a.dps_travel_time_fee_local) dps_travel_time_fee_local,\n",
    "        a.dps_surge_fee_local dps_surge_fee_local,\n",
    "        a.delivery_fee_local delivery_fee_local,\n",
    "        a.gfv_local gfv_local,\n",
    "        a.gmv_local gmv_local\n",
    "    from `fulfillment-dwh-production.cl.dps_sessions_mapped_to_orders_v2` a\n",
    "    LEFT JOIN `fulfillment-dwh-production.cl.dps_ab_test_orders_v2` b ON a.entity_id = b.entity_id AND a.order_id = b.order_id\n",
    "    LEFT JOIN `logistics-data-storage-staging.long_term_pricing.vendors_clustered_entity` e on a.entity_id = e.entity_id and a.vendor_id = e.vendor_id \n",
    "    LEFT JOIN `logistics-data-storage-staging.long_term_pricing.vendors_clustered` v on v.entity_id = a.entity_id and a.vendor_id = v.vendor_id\n",
    "    where a.created_date between DATE(\"{test_start_date}\") and DATE(\"{test_end_date}\")\n",
    "    AND b.test_name IN ({test_names})\n",
    "    AND a.is_sent\n",
    "    AND a.scheme_id IS NOT NULL\n",
    "    AND a.entity_id = (\"{entity_id}\")\n",
    "    AND a.scheme_id in (634,635)\n",
    "    AND a.is_sent -- Successful orders\n",
    "    AND a.is_in_treatment = true \n",
    "    AND a.is_own_delivery -- OD orders only\n",
    "    and e.cluster is not null\n",
    "    and v.cluster is not null\n",
    "    AND a.variant != \"Original\" -- Exclude orders from ASAs\n",
    "    AND a.is_match_experiment_vertical\n",
    "    AND e.cluster not in ('Insufficient data')\n",
    "    AND v.cluster not in ('Insufficient data')\n",
    ")\n",
    "\n",
    "\n",
    ", dps_order_with_pm as (\n",
    "    SELECT \n",
    "    dps.*\n",
    "    , sch.* EXCEPT(entity_id, scheme_id, scheme_active_from, scheme_active_to)\n",
    "    , (SELECT MIN(tier) + 1 as tier\n",
    "        FROM UNNEST(travel_time_config) tt\n",
    "        WITH OFFSET as tier \n",
    "        WHERE dps_travel_time <= IFNULL(tt.travel_time_threshold,9999) \n",
    "    ) AS tt_tier\n",
    "    from dps_order_raw dps\n",
    "    LEFT JOIN load_scheme_data sch\n",
    "      ON dps.entity_id = sch.entity_id\n",
    "      AND dps.scheme_id = sch.scheme_id\n",
    "      AND order_placed_at >= scheme_active_from \n",
    "      AND order_placed_at < scheme_active_to \n",
    ")\n",
    "  SELECT\n",
    "  a.created_date_utc,\n",
    "  a.variant,\n",
    "  -- Vendor data and information on the delivery\n",
    "  a.vendor_id,\n",
    "  a.entity_cluster,\n",
    "  a.area_cluster,\n",
    "  -- Business KPIs (These are the components of profit)\n",
    "  a.platform_order_code platform_order_code,\n",
    "  a.dps_travel_time_fee_local,\n",
    "  a.dps_delivery_fee_local dps_delivery_fee_local,\n",
    "  --avg(a.dps_travel_time_fee_local) dps_travel_time_fee_local,\n",
    "  a.dps_surge_fee_local dps_surge_fee_local,\n",
    "  a.delivery_fee_local delivery_fee_local,\n",
    "  a.gfv_local gfv_local,\n",
    "  a.gmv_local gmv_local,\n",
    "  cast(a.tt_tier as string) tt_tier\n",
    "from dps_order_with_pm as a\n",
    " \"\"\".format(test_names=', '.join(test_names), entity_id=entity_id, test_start_date=test_start_date, test_end_date=test_end_date)\n",
    "# Execute the orders query\n",
    "df_test_data = pd.read_gbq(test_query, project_id='logistics-customer-staging', dialect='standard')##, credentials=credentials)\n",
    "df_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data['delivery_fee_local'] = df_test_data['delivery_fee_local'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data['gfv_local'] = df_test_data['gfv_local'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data['df_afv'] = (df_test_data['delivery_fee_local'] / df_test_data['gfv_local'])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY CLUSTERING BY ENTITY CLUSTER (OMAR CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run the bootstrapping function sequentially\n",
    "vendor_labels = [\"Low Basket, low Distance\", \"Low basket, high distance\", \"Central cluster\", \"High basket, low distance\", \"High basket, high distance\"]\n",
    "price_tiers = [\"1\",\"2\",\"3\",\"4\", \"5\"]\n",
    "sim_results = []\n",
    "sim_counter = 1\n",
    "for i in test_names:\n",
    "    for j in vendor_labels:\n",
    "        for l in price_tiers:\n",
    "            df_sub_test = df_test_data[(df_test_data[\"area_cluster\"] == j) & (df_test_data[\"tt_tier\"] == l)]\n",
    "            \n",
    "            # Elasticity calculated by pct difference in no. of transactions / pct difference in average DF\n",
    "            for k in range(1, num_bootstrap_samples + 1):\n",
    "                print(f\"Iteration {sim_counter}. Sampling with the following parameters --> vendor_group_label: {j}, price_tier:{l}, sample_num: {k}\")\n",
    "                df_ctl_sample = df_sub_test[df_sub_test[\"variant\"] == \"Control\"].sample(frac=1, replace=True)\n",
    "                df_var_sample = df_sub_test[df_sub_test[\"variant\"] == \"Variation1\"].sample(frac=1, replace=True)\n",
    "                # df_ctl_sample = df_ctl.sample(frac = 1, replace = True)            \n",
    "                # df_var_sample = df_var.sample(frac=1, replace = True)\n",
    "                num_orders_ctl = df_ctl_sample[\"platform_order_code\"].nunique()\n",
    "                num_orders_var = df_var_sample[\"platform_order_code\"].nunique()\n",
    "\n",
    "                    # avg_df_ctl = df_ctl_sample[\"delivery_fee_local\"].avg()\n",
    "                    # avg_df_var = df_var_sample[\"delivery_fee_local\"].avg()\n",
    "                avg_df_ctl = df_ctl_sample[\"delivery_fee_local\"].sum() / num_orders_ctl\n",
    "                avg_df_var = df_var_sample[\"delivery_fee_local\"].sum() / num_orders_var\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                pct_diff_orders = float((num_orders_var - num_orders_ctl) / num_orders_ctl)\n",
    "                pct_diff_avg_df = float((avg_df_var - avg_df_ctl) / avg_df_ctl)\n",
    "\n",
    "                elasticity = pct_diff_orders / pct_diff_avg_df\n",
    "                avg_df_afv_var = float(df_var_sample[\"delivery_fee_local\"].sum()/df_var_sample[\"gfv_local\"].sum())\n",
    "\n",
    "                output_dict = {\n",
    "                    \"test_name\": 'CL_20221201_R_B0_O_ElasticityCLRestaurants',\n",
    "                    \"vendor_group_label\": j,\n",
    "                    \"price_tier\": l,\n",
    "                    \"sample_num\": k,\n",
    "                    \"elasticity\": elasticity,\n",
    "                    \"pct_diff_orders\": pct_diff_orders,\n",
    "                    \"pct_diff_avg_df\": pct_diff_avg_df,\n",
    "                    \"df_afv\": avg_df_afv_var\n",
    "                }\n",
    "\n",
    "                sim_results.append(output_dict)\n",
    "                    \n",
    "                    # Increment the sim counter\n",
    "                sim_counter += 1\n",
    "\n",
    "df_sim_results = pd.DataFrame(sim_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Area clustering modularized (Tincho proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = df_test_data[df_test_data['variant']==\"Control\"]\n",
    "df_variant_1 = df_test_data[df_test_data['variant']=='Variation1']\n",
    "\n",
    "df_control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the bootstrapping function sequentially\n",
    "vendor_labels = [\"Low Basket, low Distance\", \"Low basket, high distance\", \"Central cluster\", \"High basket, low distance\", \"High basket, high distance\"]\n",
    "price_tiers = [\"1\",\"2\",\"3\",\"4\", \"5\"]\n",
    "sim_results = []\n",
    "sim_counter = 1\n",
    "for i in test_names:\n",
    "    for j in vendor_labels:\n",
    "        #     # Further filter the data based on the vendor labels\n",
    "        print(j)\n",
    "        if j == \"Low Basket, low Distance\":\n",
    "            df_var = df_variant_1[df_variant_1[\"entity_cluster\"] == ld_lb_tg]\n",
    "            df_ctl = df_control[df_control[\"entity_cluster\"] == ld_lb_tg]\n",
    "           # print(df_ctl)\n",
    "        elif j == \"Low Basket, high Distance\":\n",
    "            df_var = df_variant_1[df_variant_1[\"entity_cluster\"] == hd_lb_tg]\n",
    "            df_ctl = df_control[df_control[\"entity_cluster\"] == hd_lb_tg]\n",
    "        elif j == \"Central cluster\":\n",
    "            df_var = df_variant_1[df_variant_1[\"entity_cluster\"] == central_tg]\n",
    "            df_ctl = df_control[df_control[\"entity_cluster\"] == central_tg]\n",
    "        elif j == \"Low distance, high basket\":\n",
    "            df_var = df_variant_1[df_variant_1[\"entity_cluster\"] == ld_hb_tg]\n",
    "            df_ctl = df_control[df_control[\"entity_cluster\"] == ld_hb_tg]\n",
    "        elif j == \"High Basket, high distance\":\n",
    "            df_var = df_variant_1[df_variant_1[\"entity_cluster\"]== hd_hb_tg]\n",
    "            df_ctl = df_control[df_control[\"entity_cluster\"] == hd_hb_tg]\n",
    "        \n",
    "        #  # Further filter the data based on price tiers\n",
    "        for l in price_tiers:\n",
    "            print(l)\n",
    "            if l == \"1st tier\":\n",
    "                df_var = df_variant_1[df_variant_1[\"tt_tier\"] == tier_1]\n",
    "                df_ctl = df_control[df_control[\"tt_tier\"] == tier_1]\n",
    "            # print(df_ctl)\n",
    "            elif k == \"2nd tier\":\n",
    "                df_var = df_variant_1[df_variant_1[\"tt_tier\"] == tier_2]\n",
    "                df_ctl = df_control[df_control[\"tt_tier\"] == tier_2]\n",
    "            elif k == \"3rd tier\":\n",
    "                df_var = df_variant_1[df_variant_1[\"tt_tier\"] == tier_3]\n",
    "                df_ctl = df_control[df_control[\"tt_tier\"] == tier_3]\n",
    "            elif l == \"4th tier\":\n",
    "                df_var = df_variant_1[df_variant_1[\"tt_tier\"] == tier_4]\n",
    "                df_ctl = df_control[df_control[\"tt_tier\"] == tier_4]\n",
    "            elif l == \"5th tier\":\n",
    "                df_var = df_variant_1[df_variant_1[\"tt_tier\"]== tier_5]\n",
    "                df_ctl = df_control[df_control[\"tt_tier\"] == tier_5]\n",
    "           \n",
    "            \n",
    "            # Elasticity calculated by pct difference in no. of transactions / pct difference in average DF\n",
    "            for k in range(1, num_bootstrap_samples + 1):\n",
    "                print(f\"Iteration {sim_counter}. Sampling with the following parameters --> vendor_group_label: {j}, price_tier:{l}, sample_num: {k}\")\n",
    "        \n",
    "                df_ctl_sample = df_ctl.sample(frac = 1, replace = True)\n",
    "                df_var_sample = df_var.sample(frac=1, replace = True)\n",
    "                num_orders_ctl = df_ctl_sample[\"platform_order_code\"].nunique()\n",
    "                num_orders_var = df_var_sample[\"platform_order_code\"].nunique()\n",
    "\n",
    "                    # avg_df_ctl = df_ctl_sample[\"delivery_fee_local\"].avg()\n",
    "                    # avg_df_var = df_var_sample[\"delivery_fee_local\"].avg()\n",
    "                avg_df_ctl = df_ctl_sample[\"delivery_fee_local\"].sum() / num_orders_ctl\n",
    "                avg_df_var = df_var_sample[\"delivery_fee_local\"].sum() / num_orders_var\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                pct_diff_orders = float((num_orders_var - num_orders_ctl) / num_orders_ctl)\n",
    "                pct_diff_avg_df = float((avg_df_var - avg_df_ctl) / avg_df_ctl)\n",
    "\n",
    "                elasticity = pct_diff_orders / pct_diff_avg_df\n",
    "                avg_df_afv_var = float(df_var_sample[\"delivery_fee_local\"].sum()/df_var_sample[\"gfv_local\"].sum())\n",
    "\n",
    "                output_dict = {\n",
    "                    \"test_name\": 'CL_20221201_R_B0_O_ElasticityCLRestaurants',\n",
    "                    \"vendor_group_label\": j,\n",
    "                    \"price_tier\": l,\n",
    "                    \"sample_num\": k,\n",
    "                    \"elasticity\": elasticity,\n",
    "                    \"pct_diff_orders\": pct_diff_orders,\n",
    "                    \"pct_diff_avg_df\": pct_diff_avg_df,\n",
    "                    \"df_afv\": avg_df_afv_var\n",
    "                }\n",
    "\n",
    "                sim_results.append(output_dict)\n",
    "                    \n",
    "                    # Increment the sim counter\n",
    "                sim_counter += 1\n",
    "\n",
    "df_sim_results = pd.DataFrame(sim_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean elasticity of All the clusters per price tier.\n",
    "def percentile_left(x):\n",
    "    return x.quantile(left_threshold)\n",
    "\n",
    "def percentile_right(x):\n",
    "    return x.quantile(right_threshold)\n",
    "\n",
    "list_of_agg_functions = [\"mean\", percentile_left, percentile_right]\n",
    "agg_func_selection = {\"elasticity\": list_of_agg_functions, \"df_afv\": list_of_agg_functions, \"pct_diff_orders\": list_of_agg_functions, \"pct_diff_avg_df\": list_of_agg_functions}\n",
    "df_stats = df_sim_results.groupby([\"test_name\",\"price_tier\", \"vendor_group_label\"])[[\"elasticity\", \"pct_diff_orders\", \"pct_diff_avg_df\", \"df_afv\"]].agg(agg_func_selection).reset_index()\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_elas = -4.0\n",
    "max_elas = 4.0\n",
    "df_sim_filtered = df_sim_results[(df_sim_results['elasticity'] >= min_elas) & (df_sim_results['elasticity'] <= max_elas)]\n",
    "df_sim_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset by relevant columns\n",
    "df_filtered = df_sim_filtered[['price_tier', 'vendor_group_label', 'elasticity']]\n",
    "\n",
    "# Generate a subplot for each price tier\n",
    "fig, axs = plt.subplots(len(df_filtered['price_tier'].unique()), figsize=(10, 6*len(df_filtered['price_tier'].unique())))\n",
    "\n",
    "# Iterate over price tier values and create the histograms\n",
    "for i, price_tier in enumerate(df_filtered['price_tier'].unique()):\n",
    "    ax = axs[i] if len(df_filtered['price_tier'].unique()) > 1 else axs\n",
    "    filtered_data = df_filtered[df_filtered['price_tier'] == price_tier]\n",
    "    for vendor_group_label in filtered_data['vendor_group_label'].unique():\n",
    "        vendor_data = filtered_data[filtered_data['vendor_group_label'] == vendor_group_label]\n",
    "        ax.hist(vendor_data['elasticity'], bins=20, alpha=0.5, label=vendor_group_label)\n",
    "    ax.set_title(f'Price Tier: {price_tier}')\n",
    "    ax.set_xlabel('Elasticity')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust the space between the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('laburo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c42c203fadd025566f6ed483d4fdb6c2617bd546fe65e84c3fadad808b3d8c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
